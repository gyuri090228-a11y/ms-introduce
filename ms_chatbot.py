# ğŸ’¬ ëª…ì‹ ì—¬ìê³ ë“±í•™êµ Q&A ì±—ë´‡ (PDF ê¸°ë°˜ RAG)
import os
import streamlit as st
import nest_asyncio

# Streamlitì—ì„œ ë¹„ë™ê¸° ì‘ì—…ì„ ìœ„í•œ ì´ë²¤íŠ¸ ë£¨í”„ ì„¤ì •
nest_asyncio.apply()

# LangChain ë° Google GenAI ê´€ë ¨ ëª¨ë“ˆ
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories.streamlit import StreamlitChatMessageHistory
from langchain_core.output_parsers import StrOutputParser
from langchain_core.documents import Document
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
from langchain.schema.runnable import RunnablePassthrough

# --- 1. Gemini API í‚¤ ì„¤ì • ---
# NOTE: ì‹¤ì œ Streamlit í™˜ê²½ì—ì„œëŠ” st.secrets["GOOGLE_API_KEY"]ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
# ì´ í™˜ê²½ì—ì„œëŠ” os.environì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
try:
    if "GOOGLE_API_KEY" not in os.environ:
        # ì´ ë¶€ë¶„ì€ ì‹¤ì œ Streamlit ë°°í¬ ì‹œ st.secretsì—ì„œ ê°€ì ¸ì˜¤ë„ë¡ ìˆ˜ì • í•„ìš”
        # st.error("âš ï¸ GOOGLE_API_KEYë¥¼ í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” Streamlit Secretsì— ì„¤ì •í•´ì£¼ì„¸ìš”!")
        # st.stop()
        pass # í˜„ì¬ ì‹¤í–‰ í™˜ê²½ì—ì„œëŠ” API Keyê°€ ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
except Exception as e:
    # st.error("âš ï¸ GOOGLE_API_KEYë¥¼ Streamlit Secretsì— ì„¤ì •í•´ì£¼ì„¸ìš”!")
    # st.stop()
    pass

# --- 2. PDF ë‚´ìš©ì„ Document ê°ì²´ë¡œ ë³€í™˜ ---
# ì²¨ë¶€ëœ PDFì˜ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•˜ì—¬ LangChain Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“­ë‹ˆë‹¤.
# ì‹¤ì œ RAG êµ¬í˜„ì—ì„œëŠ” Vector Storeì™€ Embedding ëª¨ë¸ì´ í•„ìš”í•˜ì§€ë§Œ,
# ì—¬ê¸°ì„œëŠ” ì œê³µëœ í…ìŠ¤íŠ¸ê°€ ë§¤ìš° ì§§ìœ¼ë¯€ë¡œ **Stuffing ë°©ì‹**ìœ¼ë¡œ ë‹¨ìˆœí™”í•˜ì—¬ êµ¬í˜„í•©ë‹ˆë‹¤.
# (ë¬¸ì„œ ì „ì²´ë¥¼ í”„ë¡¬í”„íŠ¸ì— ë„£ì–´ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë°©ì‹)

# PDFì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•© (ì†ŒìŠ¤ì—ì„œ ë‚´ìš©ë§Œ ì¶”ì¶œ)
# ì£¼ì˜: ì´ ì½”ë“œëŠ” ì œê³µëœ PDF ë‚´ìš©ì„ í•˜ë“œì½”ë”©í•œ ê²ƒì…ë‹ˆë‹¤. ì‹¤ì œ íŒŒì¼ ì²˜ë¦¬ ë¡œì§ì´ ì•„ë‹™ë‹ˆë‹¤.
pdf_content_text = """
ëª…ì‹ ì—¬ìê³ ë“±í•™êµì˜ ìœ„ì¹˜ëŠ” ëŒ€í•œë¯¼êµ­ ì¸ì²œê´‘ì•½ì‹œ ë¶€í‰êµ¬ ì‚°ê³¡ë™ ë¶€í‰êµ¬ ì›ì ë¡œ 260ì— ìœ„ì¹˜í•´ ìˆë‹¤. ì‚¬ë¦½ê³ ë“±í•™êµì´ë‹¤.
ì°½ë¦½ì€ 1970ë…„ì— í–ˆë‹¤. ë¬¸ì˜ í•  ìˆ˜ ìˆëŠ” ì „í™”ë²ˆí˜¸ëŠ” 032-502-3088.
êµí›ˆì€ ì„±ì‹¤ì´ë‹¤. êµëª©ì€ í–¥ë‚˜ë¬´. êµí™”ëŠ” ì¥ë¯¸ì´ë‹¤. í•™êµ í™ˆí˜ì´ì§€ëŠ” https://msrose.icehs.kr/main.doì´ë‹¤.
êµëª…(ë°ì„ ëª…(æ˜), ìƒˆë¡œìš¸ ì‹ (æ–°))ì€ ë°ê³  ìƒˆë¡œìš°ë©°, ê´‘ëª…í•˜ì—¬ ë‚ ë¡œ ìƒˆë¡œì›Œì§€ëŠ” ì§„ë³´ ë°œì „í•˜ëŠ” í•™êµë¥¼ ì˜ë¯¸í•œë‹¤.
êµí‘œëŠ” ë‘¥ê·¼ ì›(ìš°ì£¼, ì„±ì‹¤, ì‹ ì˜, ë´‰ì‚¬ì˜ ì´ë…, ì§„ë¦¬ ë¶ˆë³€ê³¼ ìˆœí™˜, ì™„ì „í•œ í•˜ë‚˜ ìƒì§•)ê³¼ ì •ì‚¬ê°í˜•(ì•ˆì •, ê²¬ê³ í•¨ ìƒì§•)ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆê³ , ë¶‰ì€ ìƒ‰ì€ ìƒëª…ê³¼ ì‚¬ë‘ì„ ì˜ë¯¸í•˜ë©°, 1971 ìˆ«ìëŠ” ì„¤ë¦½ë…„ë„ë¥¼ ì˜ë¯¸í•œë‹¤.
êµê¸°ëŠ” ë°œì „í•˜ëŠ” ì—­ì‚¬ì™€ ë¯¸ë˜ë¥¼ ì •ì ìœ¼ë¡œ ìƒì§•í•˜ë©°, ì´ˆë¡ìƒ‰ ë°”íƒ•ì€ ë†’ì€ ê¸°ìƒê³¼ ë¶€í¥ì˜ ì˜ì§€, ë¬´í•œí•œ ê°€ëŠ¥ì„±ì„ ì˜ë¯¸í•œë‹¤. í•˜ë‹¨ì—ëŠ” í•™êµëª…ì´ ê¸ˆìƒ‰ìœ¼ë¡œ ììˆ˜ë˜ì–´ ìˆë‹¤.
ì—­ëŒ€ ì´ì‚¬ì¥ì€ ì´ì •ì›”, ê°•ì¢…ë½, ê°•ì§€ì›ì´ë‹¤.
ì—­ëŒ€ êµì¥ì€ ì´ì£¼í™˜, ìµœì›íƒ, ì´ì°½ë´‰, ê¹€ìš©ì˜¤, ë¦¬ë²”ì§, ê¶Œìœ ìƒ, ì¡°ê·œë°°, í•œë³‘ì˜¥, ì²œë¯¼ìˆ˜, ìœ¤ë™ì¶˜, ì´ë‚¨ì •, ê°•ì¸ìˆ˜, ì´ì˜ì, ì´ì¢…í˜, ê¶Œìš©ì„, ìœ¤ì¸ë¦¬ ìˆœì´ë‹¤.
2025í•™ë…„ë„ ì…í•™ìƒ 3ê°œë…„ê°„ êµìœ¡ê³¼ì • í¸ì„±í‘œì— í¬í•¨ëœ ê³¼ëª© ì •ë³´:
- **êµ­ì–´:** ê³µí†µêµ­ì–´1, ê³µí†µêµ­ì–´2, ë…ì„œì™€ ì‘ë¬¸, ë¬¸í•™ (ì´ì´ìˆ˜ 14ë‹¨ìœ„, í•„ìˆ˜ 10ë‹¨ìœ„)
- **ìˆ˜í•™:** ê³µí†µìˆ˜í•™1, ê³µí†µìˆ˜í•™2, ëŒ€ìˆ˜, ë¯¸ì ë¶„ 1 (ì´ì´ìˆ˜ 13ë‹¨ìœ„, í•„ìˆ˜ 10ë‹¨ìœ„)
- **ì˜ì–´:** ê³µí†µì˜ì–´1, ê³µí†µì˜ì–´2, ì˜ì–´ 1, ì˜ì–´ II (ì´ì´ìˆ˜ 16ë‹¨ìœ„, í•„ìˆ˜ 10ë‹¨ìœ„)
- **ì²´ìœ¡:** ì²´ìœ¡ 1, ì²´ìœ¡ Iâ…¡, ìŠ¤í¬ì¸  ë¬¸í™”, ìŠ¤í¬ì¸  ê³¼í•™, ìŠ¤í¬ì¸  ìƒí™œ 1, ìŠ¤í¬ì¸  ìƒí™œ â…¡ (ì´ì´ìˆ˜ 10ë‹¨ìœ„, í•„ìˆ˜ 10ë‹¨ìœ„)
- **ì˜ˆìˆ :** ìŒì•…, ë¯¸ìˆ , ìŒì•… ê°ìƒê³¼ ë¹„í‰, ë¯¸ìˆ  ê°ìƒê³¼ ë¹„í‰ (ì´ì´ìˆ˜ 10ë‹¨ìœ„, í•„ìˆ˜ 10ë‹¨ìœ„)
- **ì‚¬íšŒ(ì—­ì‚¬/ë„ë• í¬í•¨):** í•œêµ­ì‚¬ 1, í•œêµ­ì‚¬ â…¡, í†µí•©ì‚¬íšŒ 1, í†µí•©ì‚¬íšŒ II (ì´ì´ìˆ˜ 12ë‹¨ìœ„, í•„ìˆ˜ 10ë‹¨ìœ„)
- **ê³¼í•™:** í†µí•©ê³¼í•™ 1, í†µí•©ê³¼í•™ II, ê³¼í•™íƒêµ¬ì‹¤í—˜ 1, ê³¼í•™íƒêµ¬ì‹¤í—˜ II (ì´ì´ìˆ˜ 8ë‹¨ìœ„, í•„ìˆ˜ 12ë‹¨ìœ„)
- **ê¸°ìˆ Â·ê°€ì •/ì •ë³´:** ì •ë³´, ì§€ì‹ ì¬ì‚° ì¼ë°˜ (ì´ì´ìˆ˜ 8ë‹¨ìœ„, í•„ìˆ˜ 0ë‹¨ìœ„)
- **êµì–‘:** ì§„ë¡œì™€ ì§ì—…, ìƒíƒœì™€ í™˜ê²½, ì¸ê°„ê³¼ ì² í•™, ì¸ê°„ê³¼ ì‹¬ë¦¬, êµìœ¡ì˜ ì´í•´, ë³´ê±´ (ì„ íƒ)
- **ì œ2ì™¸êµ­ì–´/í•œë¬¸:** ì¤‘êµ­ ë¬¸í™”, ì¼ë³¸ ë¬¸í™”, ì–¸ì–´ìƒí™œê³¼ í•œì, ì¤‘êµ­ì–´ 1, ì¼ë³¸ì–´ 1, í•œë¬¸ (ìœµí•©/ì¼ë°˜ ì„ íƒ)
- **ì„ íƒ ê³¼ëª© (ì¼ë¶€):** ê¸°í•˜, ì„¸ê³„ ë¬¸í™”ì™€ ì˜ì–´, ê¸°ì´ˆ ì²´ìœ¡ ì „ê³µ ì‹¤ê¸°, ë¯¸ìˆ ê³¼ ë§¤ì²´, ìŒì•…ê³¼ ë¬¸í™”, ì •ë³´ê³¼í•™, ì •ì¹˜, ìœ¤ë¦¬ì™€ ì‚¬ìƒ, ì—­í•™ê³¼ ì—ë„ˆì§€, ë¬¼ì§ˆê³¼ ì—ë„ˆì§€, ì„¸í¬ì™€ ë¬¼ì§ˆëŒ€ì‚¬, ì§€êµ¬ì‹œìŠ¤í…œê³¼í•™, ì–¸ì–´ìƒí™œ íƒêµ¬ ë“± ë‹¤ìˆ˜ ê³¼ëª©.
ì´ ì´ìˆ˜ ë‹¨ìœ„ëŠ” í•™ê¸°ë³„ 32ë‹¨ìœ„ (6í•™ê¸°), ì´ **192ë‹¨ìœ„**ì´ë‹¤. (ì°½ì˜ì  ì²´í—˜í™œë™ 18ë‹¨ìœ„ í¬í•¨).
"""

# í•˜ë‚˜ì˜ í° Documentë¡œ ë§Œë“¦ (Stuffing ë°©ì‹)
retrieved_docs = [Document(page_content=pdf_content_text, metadata={"source": "ëª…ì‹ ì—¬ê³  ì†Œê°œ PDF"})]

# ê°„ë‹¨í•œ ì¸ë©”ëª¨ë¦¬ ê²€ìƒ‰ê¸° (í•­ìƒ ëª¨ë“  ë¬¸ì„œë¥¼ ë°˜í™˜)
# ì‹¤ì œ RAGì—ì„œëŠ” Vector Store ê¸°ë°˜ì˜ Retrieverë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
class SimpleInMemoryRetriever:
    def __init__(self, documents):
        self.documents = documents

    def get_relevant_documents(self, query):
        # ì¿¼ë¦¬ì— ê´€ê³„ì—†ì´ ëª¨ë“  ë¬¸ì„œë¥¼ ë°˜í™˜ (Stuffing ë°©ì‹ì˜ ë‹¨ìˆœí™”)
        return self.documents

retriever = SimpleInMemoryRetriever(retrieved_docs)


# --- 3. LLM ë° í”„ë¡¬í”„íŠ¸ ì„¤ì • (ìºì‹œ) ---
@st.cache_resource(show_spinner="ğŸ¤– Q&A ì±—ë´‡ ëª¨ë¸ ë° ì§€ì‹ ê¸°ë°˜ ë¡œë”© ì¤‘...")
def get_qa_chain(selected_model):
    """
    RAG ê¸°ë°˜ Q&A ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        llm = ChatGoogleGenerativeAI(
            model=selected_model,
            temperature=0.0, # Q&AëŠ” ì°½ì˜ì„±ë³´ë‹¤ ì •í™•ì„±ì´ ì¤‘ìš”í•˜ë¯€ë¡œ 0.0 ì„¤ì •
            convert_system_message_to_human=True
        )
    except Exception as e:
        st.error(f"âŒ Gemini ëª¨ë¸ '{selected_model}' ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        st.info("ğŸ’¡ API í‚¤ê°€ ìœ íš¨í•œì§€, ëª¨ë¸ ì´ë¦„ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ë³´ì„¸ìš”.")
        st.stop()

    # 1. ë¬¸ì„œ ê²°í•© ì²´ì¸ (Document Combination Chain)
    # ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” í”„ë¡¬í”„íŠ¸
    qa_system_prompt = (
        "ë‹¹ì‹ ì€ ëª…ì‹ ì—¬ìê³ ë“±í•™êµì˜ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì¹œì ˆí•˜ê³  ì •í™•í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ 'ì œë¯¸ë‚˜ì´'ì…ë‹ˆë‹¤. "
        "í•­ìƒ í•œêµ­ì–´ì™€ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ë©°, ì œê³µëœ **ë‹¤ìŒ ì •ë³´(context)**ë§Œì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”. "
        "ë§Œì•½ ì •ë³´ì— ì—†ëŠ” ë‚´ìš©ì´ë¼ë©´ 'ì£„ì†¡í•˜ì§€ë§Œ ì œê³µëœ ìë£Œì—ëŠ” í•´ë‹¹ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ë‹µí•˜ì„¸ìš”. "
        "ë‹µë³€ ì‹œ ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•´ ì£¼ì„¸ìš”. ğŸ¤–\n\n"
        "**Context:**\n{context}"
    )
    qa_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", qa_system_prompt),
            MessagesPlaceholder("chat_history"),
            ("human", "{input}"),
        ]
    )

    document_chain = create_stuff_documents_chain(llm, qa_prompt)

    # 2. ê²€ìƒ‰ ì²´ì¸ (Retrieval Chain)
    # ê²€ìƒ‰ëœ ë¬¸ì„œì™€ ì‚¬ìš©ì ì…ë ¥ì„ ê²°í•© ì²´ì¸ì— ì „ë‹¬í•˜ëŠ” ì „ì²´ ì²´ì¸
    retrieval_chain = create_retrieval_chain(retriever, document_chain)
    
    return retrieval_chain

# --- 4. Streamlit UI ì„¤ì • ---

st.header("ëª…ì‹ ì—¬ìê³ ë“±í•™êµ Q&A ì±—ë´‡ ğŸ«")
st.info("ì²¨ë¶€ëœ PDF íŒŒì¼ì„ ê¸°ë°˜ìœ¼ë¡œ ëª…ì‹ ì—¬ê³ ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”.")

# ì±„íŒ… ê¸°ë¡ì„ Streamlitì˜ ì„¸ì…˜ ìƒíƒœ(session_state)ì— ì €ì¥
chat_history = StreamlitChatMessageHistory(key="chat_messages")

# ëª¨ë¸ ì„ íƒ
option = st.selectbox("Select Gemini Model",
    ("gemini-2.5-flash", "gemini-2.5-pro", "gemini-2.0-flash-exp"),
    index=0,
    help="ê°€ì¥ ë¹ ë¥´ê³  íš¨ìœ¨ì ì¸ 2.5 Flash ëª¨ë¸ì„ ì¶”ì²œí•©ë‹ˆë‹¤."
)

# ì„ íƒëœ ëª¨ë¸ë¡œ LLM ì²´ì¸ ê°€ì ¸ì˜¤ê¸°
retrieval_chain = get_qa_chain(option)

# ëŒ€í™” ê¸°ë¡ì„ ê´€ë¦¬í•˜ëŠ” Runnable ìƒì„±
# LangChainì—ì„œëŠ” `RunnableWithMessageHistory`ë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ê¸°ë¡ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
conversational_retrieval_chain = RunnableWithMessageHistory(
    retrieval_chain,
    lambda session_id: chat_history,
    input_messages_key="input",
    history_messages_key="chat_history", # history ëŒ€ì‹  qa_promptì— ì„¤ì •í•œ chat_history í‚¤ ì‚¬ìš©
)

# --- 5. ì±„íŒ… UI ë¡œì§ ---

# ì²« ë°©ë¬¸ ì‹œ í™˜ì˜ ë©”ì‹œì§€ ì¶”ê°€
if not chat_history.messages:
    chat_history.add_ai_message("ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ëª…ì‹ ì—¬ê³  PDF ê¸°ë°˜ Q&A ì±—ë´‡ 'ì œë¯¸ë‚˜ì´'ì…ë‹ˆë‹¤. ğŸ˜Š í•™êµ ìœ„ì¹˜, êµí›ˆ, êµìœ¡ê³¼ì • ë“±ì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”!")

# ì´ì „ ëŒ€í™” ê¸°ë¡ ëª¨ë‘ ì¶œë ¥
for msg in chat_history.messages:
    st.chat_message(msg.type).write(msg.content)

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if prompt_message := st.chat_input("ëª…ì‹ ì—¬ê³ ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”..."):
    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë©”ì‹œì§€ ì¶œë ¥
    st.chat_message("human").write(prompt_message)
    
    # AI ì‘ë‹µ ìƒì„± ë° ì¶œë ¥
    with st.chat_message("ai"):
        with st.spinner("ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ë‹µë³€ì„ ìƒì„± ì¤‘..."):
            # config: session_idëŠ” ì•„ë¬´ ê°’ì´ë‚˜ ë„£ì–´ë„ chat_historyë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •ë¨
            config = {"configurable": {"session_id": "any_id"}}
            
            # RAG ì²´ì¸ ì‹¤í–‰
            # ë°˜í™˜ë˜ëŠ” ê²°ê³¼ëŠ” {'answer': '...', 'context': [...]} í˜•íƒœì…ë‹ˆë‹¤.
            response_data = conversational_retrieval_chain.invoke(
                {"input": prompt_message},
                config
            )
            
            # ë‹µë³€ ì¶œë ¥
            st.write(response_data["answer"])
            
            # (ì„ íƒ ì‚¬í•­) ê²€ìƒ‰ëœ ë¬¸ì„œ(context)ë¥¼ ë³´ì—¬ì¤Œ
            # with st.expander("ğŸ” ê²€ìƒ‰ëœ ì •ë³´ (Context)"):
            #     st.json(response_data["context"])
